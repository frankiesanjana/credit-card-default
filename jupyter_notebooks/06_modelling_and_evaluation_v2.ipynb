{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Notebook 06 - Modelling and Evaluation v2"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fit and evaluate a classification model that predicts whether or not an existing customer will default in the following month\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Combined data cleaning and feature engineering pipeline\n",
        "\n",
        "## Outputs\n",
        "\n",
        "\n",
        "* Test and train sets for the current split and target imbalance correction method\n",
        "* Pipeline for modelling and hyperparameter optimisation\n",
        "* Feature importance plot\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* This notebook continues the work done in the previous notebook where initial modelling and hyperparameter optimisation was conducted. Different techniques are tried here in an attempt to improve model performance."
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* This notebook is stored in the `jupyter_notebooks` subfolder\n",
        "* The current working directory therefore needs to be changed to the workspace, i.e., the working directory needs to be changed from the current folder to its parent folder"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Firstly, the current directory is accessed with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\franc\\\\credit-card-default\\\\jupyter_notebooks'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "Next, the working directory is set as the parent of the current `jupyter_notebooks` directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory\n",
        "* This allows access to all the files and folders within the workspace, rather than solely those within the `jupyter_notebooks` directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You set a new current directory\n"
          ]
        }
      ],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Finally, confirm that the new current directory has been successfully set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'c:\\\\Users\\\\franc\\\\credit-card-default'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load data and restate pipelines"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data is loaded from the outputs/datasets/collection folder:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>LIMIT_BAL</th>\n",
              "      <th>SEX</th>\n",
              "      <th>EDUCATION</th>\n",
              "      <th>MARRIAGE</th>\n",
              "      <th>AGE</th>\n",
              "      <th>PAY_0</th>\n",
              "      <th>PAY_2</th>\n",
              "      <th>PAY_3</th>\n",
              "      <th>PAY_4</th>\n",
              "      <th>...</th>\n",
              "      <th>BILL_AMT4</th>\n",
              "      <th>BILL_AMT5</th>\n",
              "      <th>BILL_AMT6</th>\n",
              "      <th>PAY_AMT1</th>\n",
              "      <th>PAY_AMT2</th>\n",
              "      <th>PAY_AMT3</th>\n",
              "      <th>PAY_AMT4</th>\n",
              "      <th>PAY_AMT5</th>\n",
              "      <th>PAY_AMT6</th>\n",
              "      <th>default.payment.next.month</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>20000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>24</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>120000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>26</td>\n",
              "      <td>-1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3272.0</td>\n",
              "      <td>3455.0</td>\n",
              "      <td>3261.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>90000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>14331.0</td>\n",
              "      <td>14948.0</td>\n",
              "      <td>15549.0</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>28314.0</td>\n",
              "      <td>28959.0</td>\n",
              "      <td>29547.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>50000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>57</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>20940.0</td>\n",
              "      <td>19146.0</td>\n",
              "      <td>19131.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>36681.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 25 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
              "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
              "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
              "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
              "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
              "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
              "\n",
              "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
              "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
              "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
              "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
              "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
              "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
              "\n",
              "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
              "0       0.0       0.0       0.0                           1  \n",
              "1    1000.0       0.0    2000.0                           1  \n",
              "2    1000.0    1000.0    5000.0                           0  \n",
              "3    1100.0    1069.0    1000.0                           0  \n",
              "4    9000.0     689.0     679.0                           0  \n",
              "\n",
              "[5 rows x 25 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('outputs/datasets/collection/credit_card_data.csv')\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we restate our existing data cleaning and feature engineering pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import FunctionTransformer\n",
        "from feature_engine.selection import DropFeatures\n",
        "from feature_engine.encoding import OneHotEncoder\n",
        "\n",
        "\n",
        "def rename_columns(X):\n",
        "    X.columns = ['credit_limit', 'sex', 'education', 'marital_status',\n",
        "                 'age', 'late_sep', 'late_aug', 'late_jul', 'late_jun',\n",
        "                 'late_may', 'late_apr', 'bill_sep', 'bill_aug',\n",
        "                 'bill_jul', 'bill_jun', 'bill_may', 'bill_apr',\n",
        "                 'prev_payment_sep', 'prev_payment_aug',\n",
        "                 'prev_payment_jul', 'prev_payment_jun',\n",
        "                 'prev_payment_may', 'prev_payment_apr',\n",
        "                 'default_next_month']\n",
        "    return X\n",
        "\n",
        "\n",
        "def clean_categorical_data(X):\n",
        "    sex_mapping = {1: \"male\", 2: \"female\"}\n",
        "    education_mapping = {1: \"graduate school\", 2: \"university\", 3: \"high school\", 4: \"other\", 5: \"unknown\", 6: \"unknown\"}\n",
        "    marital_status_mapping = {0: \"unknown\", 1: \"married\", 2: \"single\", 3: \"other\"}\n",
        "    X['sex'] = X['sex'].replace(sex_mapping)\n",
        "    X['education'] = X['education'].replace(education_mapping)\n",
        "    X['marital_status'] = X['marital_status'].replace(marital_status_mapping)\n",
        "    return X\n",
        "\n",
        "\n",
        "def default_summary(X):\n",
        "    X['any_default'] = X[['late_sep', 'late_aug', 'late_jul', 'late_jun',\n",
        "                 'late_may', 'late_apr']].gt(0).any(axis=1).astype(int)\n",
        "    X['total_default'] = X[['late_sep', 'late_aug', 'late_jul', 'late_jun',\n",
        "                 'late_may', 'late_apr']].clip(lower=0).sum(axis=1)\n",
        "    X['greatest_default'] = X[['late_sep', 'late_aug', 'late_jul', 'late_jun',\n",
        "                 'late_may', 'late_apr']].clip(lower=0).max(axis=1)\n",
        "    return X\n",
        "\n",
        "\n",
        "def ordinal_encode_education(X):\n",
        "    X['education'] = X['education'].map(education_map)\n",
        "    X['education'] = X['education'].fillna(0)\n",
        "    return X\n",
        "\n",
        "variables_ohe = ['sex', 'marital_status']\n",
        "\n",
        "education_map = {\n",
        "    '0': 0,\n",
        "    'other': 0,\n",
        "    'unknown': 0,\n",
        "    'high school': 1,\n",
        "    'university': 2,\n",
        "    'graduate school': 3\n",
        "}\n",
        "\n",
        "data_cleaning_and_feature_engineering_pipeline = Pipeline([\n",
        "      ('drop',  DropFeatures(features_to_drop=['ID'])),\n",
        "      ('rename_columns', FunctionTransformer(rename_columns, validate=False)),\n",
        "      ('clean_categorical_data', FunctionTransformer(clean_categorical_data)),\n",
        "      ('add_default_summary', FunctionTransformer(default_summary)),\n",
        "      ('one_hot_encode', OneHotEncoder(variables=variables_ohe, drop_last=True)),\n",
        "      ('ordinal_encode', FunctionTransformer(ordinal_encode_education)),\n",
        "      ('drop_after_cleaning',  DropFeatures(features_to_drop=['late_sep', 'late_aug', 'late_jun',\n",
        "                                               'late_may', 'late_apr', 'bill_aug', \n",
        "                                               'bill_jul', 'bill_jun', 'bill_may', \n",
        "                                               'bill_apr', 'any_default', 'greatest_default',\n",
        "                                               'marital_status_married'])),\n",
        "])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As well as our ML pipeline for modelling and hyperparameter optimisation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\xgboost\\compat.py:93: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
            "  from pandas import MultiIndex, Int64Index\n"
          ]
        }
      ],
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Feature Selection\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# ML algorithms\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "def PipelineClf(model):\n",
        "    pipeline_base = Pipeline([\n",
        "        (\"scaler\", StandardScaler()),\n",
        "        (\"feat_selection\", SelectFromModel(model)),\n",
        "        (\"model\", model),\n",
        "    ])\n",
        "\n",
        "    return pipeline_base"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And our custom class for hyperparameter optimisation, taken from CI's WP02:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "\n",
        "class HyperparameterOptimizationSearch:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv, n_jobs, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(f\"\\nRunning GridSearchCV for {key} \\n\")\n",
        "\n",
        "            model = PipelineClf(self.models[key])\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, )\n",
        "            gs.fit(X, y)\n",
        "            self.grid_searches[key] = gs\n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                'estimator': key,\n",
        "                'min_score': min(scores),\n",
        "                'max_score': max(scores),\n",
        "                'mean_score': np.mean(scores),\n",
        "                'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params, **d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]\n",
        "                scores.append(r.reshape(len(params), 1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params, all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "        columns = ['estimator', 'min_score',\n",
        "                   'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "        return df[columns], self.grid_searches\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Prepare Data for Modelling"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Apply data cleaning and feature engineering pipeline"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As in the previous notebook, we apply the data cleaning and feature engineering pipeline:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>credit_limit</th>\n",
              "      <th>education</th>\n",
              "      <th>age</th>\n",
              "      <th>late_jul</th>\n",
              "      <th>bill_sep</th>\n",
              "      <th>prev_payment_sep</th>\n",
              "      <th>prev_payment_aug</th>\n",
              "      <th>prev_payment_jul</th>\n",
              "      <th>prev_payment_jun</th>\n",
              "      <th>prev_payment_may</th>\n",
              "      <th>prev_payment_apr</th>\n",
              "      <th>default_next_month</th>\n",
              "      <th>total_default</th>\n",
              "      <th>sex_female</th>\n",
              "      <th>marital_status_single</th>\n",
              "      <th>marital_status_other</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>20000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>24</td>\n",
              "      <td>-1</td>\n",
              "      <td>3913.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>120000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>26</td>\n",
              "      <td>0</td>\n",
              "      <td>2682.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>90000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>34</td>\n",
              "      <td>0</td>\n",
              "      <td>29239.0</td>\n",
              "      <td>1518.0</td>\n",
              "      <td>1500.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>5000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>50000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>37</td>\n",
              "      <td>0</td>\n",
              "      <td>46990.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>1100.0</td>\n",
              "      <td>1069.0</td>\n",
              "      <td>1000.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>57</td>\n",
              "      <td>-1</td>\n",
              "      <td>8617.0</td>\n",
              "      <td>2000.0</td>\n",
              "      <td>36681.0</td>\n",
              "      <td>10000.0</td>\n",
              "      <td>9000.0</td>\n",
              "      <td>689.0</td>\n",
              "      <td>679.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   credit_limit  education  age  late_jul  bill_sep  prev_payment_sep  \\\n",
              "0       20000.0        2.0   24        -1    3913.0               0.0   \n",
              "1      120000.0        2.0   26         0    2682.0               0.0   \n",
              "2       90000.0        2.0   34         0   29239.0            1518.0   \n",
              "3       50000.0        2.0   37         0   46990.0            2000.0   \n",
              "4       50000.0        2.0   57        -1    8617.0            2000.0   \n",
              "\n",
              "   prev_payment_aug  prev_payment_jul  prev_payment_jun  prev_payment_may  \\\n",
              "0             689.0               0.0               0.0               0.0   \n",
              "1            1000.0            1000.0            1000.0               0.0   \n",
              "2            1500.0            1000.0            1000.0            1000.0   \n",
              "3            2019.0            1200.0            1100.0            1069.0   \n",
              "4           36681.0           10000.0            9000.0             689.0   \n",
              "\n",
              "   prev_payment_apr  default_next_month  total_default  sex_female  \\\n",
              "0               0.0                   1              4           1   \n",
              "1            2000.0                   1              4           1   \n",
              "2            5000.0                   0              0           1   \n",
              "3            1000.0                   0              0           1   \n",
              "4             679.0                   0              0           0   \n",
              "\n",
              "   marital_status_single  marital_status_other  \n",
              "0                      0                     0  \n",
              "1                      1                     0  \n",
              "2                      1                     0  \n",
              "3                      0                     0  \n",
              "4                      0                     0  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = data_cleaning_and_feature_engineering_pipeline.fit_transform(df)\n",
        "df.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split data into train and test set"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split train and test set. Note that by keeping `random_state` the same value as in the previous notebook, we can be sure to split the data in exactly the same way.\n",
        "* We inspect the shape of each of `X_train`, `y_train`, `X_test` and `y_test` as a check that the split has worked correctly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(24000, 15) (24000,) (6000, 15) (6000,)\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    df.drop(['default_next_month'], axis=1),\n",
        "    df['default_next_month'],\n",
        "    test_size=0.2,\n",
        "    random_state=42,\n",
        ")\n",
        "\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "21753    0\n",
              "251      0\n",
              "22941    0\n",
              "618      0\n",
              "17090    0\n",
              "Name: default_next_month, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Handle Target Imbalance"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As before, we verify the distribution of the train set target:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style(\"whitegrid\")\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As before, we see that the train set is imbalanced.\n",
        "* Previously, we applied SMOTE to the train set to fix this.\n",
        "* However, we noted that this can increase the chance of overfitting the model, since using SMOTE increases the presence of characteristics in the dataset that were initially only applicable to a relatively small number of observations.\n",
        "* The models in the previous notebook were all overfitting to some degree, and this was only improved to a limited extent by hyperparameter tuning.\n",
        "* This time, we will therefore try undersampling the majority class as a method to address this.\n",
        "\n",
        "`RandomUnderSampler` is used to undersample the majority class:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10646, 15) (10646,) (6000, 15) (6000,)\n"
          ]
        }
      ],
      "source": [
        "from imblearn.under_sampling import RandomUnderSampler\n",
        "undersample = RandomUnderSampler(sampling_strategy=\"not minority\", random_state=0)\n",
        "X_train, y_train = undersample.fit_resample(X_train, y_train)\n",
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We then check the train set target distribution again after oversampling. An equal distribution is now seen:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "y_train.value_counts().plot(kind='bar', title='Train Set Target Distribution')\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train the ML pipeline to predict default in the following month"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find the most suitable algorithm for the data"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now repeat the processes from the previous notebook. First, we want to find the most suitable algorithm for the data by testing multiple algorithms using their default hyperparameters (as previously noted, the empty dictionaries in `params_quick_search` mean that the default hyperparameters will be used)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "models_quick_search = {\n",
        "    \"LogisticRegression\": LogisticRegression(random_state=0),\n",
        "    \"XGBClassifier\": XGBClassifier(random_state=0),\n",
        "    \"DecisionTreeClassifier\": DecisionTreeClassifier(random_state=0),\n",
        "    \"RandomForestClassifier\": RandomForestClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
        "    \"ExtraTreesClassifier\": ExtraTreesClassifier(random_state=0),\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "    \"BernoulliNBClassifier\": BernoulliNB(),\n",
        "    \"LinearSVCClassifier\": LinearSVC(random_state=0)\n",
        "}\n",
        "\n",
        "params_quick_search = {\n",
        "    \"LogisticRegression\": {},\n",
        "    \"XGBClassifier\": {},\n",
        "    \"DecisionTreeClassifier\": {},\n",
        "    \"RandomForestClassifier\": {},\n",
        "    \"GradientBoostingClassifier\": {},\n",
        "    \"ExtraTreesClassifier\": {},\n",
        "    \"AdaBoostClassifier\": {},\n",
        "    \"BernoulliNBClassifier\": {},\n",
        "    \"LinearSVCClassifier\": {}\n",
        "}\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now run GridSearch CV to identify the best performing algorithms for the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for LogisticRegression \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for XGBClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for DecisionTreeClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for RandomForestClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for GradientBoostingClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for ExtraTreesClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for AdaBoostClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for BernoulliNBClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "\n",
            "Running GridSearchCV for LinearSVCClassifier \n",
            "\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\utils\\deprecation.py:101: FutureWarning: Attribute coef_ was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
            "c:\\Users\\franc\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import make_scorer, f1_score\n",
        "f1_search = HyperparameterOptimizationSearch(models=models_quick_search, params=params_quick_search)\n",
        "f1_search.fit(X_train, y_train,\n",
        "           scoring =  make_scorer(f1_score),\n",
        "           n_jobs=-1, cv=5)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can check the results:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.671135</td>\n",
              "      <td>0.683448</td>\n",
              "      <td>0.701689</td>\n",
              "      <td>0.011908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.67042</td>\n",
              "      <td>0.682432</td>\n",
              "      <td>0.692969</td>\n",
              "      <td>0.008438</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.67122</td>\n",
              "      <td>0.681415</td>\n",
              "      <td>0.689518</td>\n",
              "      <td>0.00696</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.672934</td>\n",
              "      <td>0.678131</td>\n",
              "      <td>0.684739</td>\n",
              "      <td>0.005389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ExtraTreesClassifier</td>\n",
              "      <td>0.668339</td>\n",
              "      <td>0.675858</td>\n",
              "      <td>0.687898</td>\n",
              "      <td>0.007283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>BernoulliNBClassifier</td>\n",
              "      <td>0.637037</td>\n",
              "      <td>0.64612</td>\n",
              "      <td>0.653093</td>\n",
              "      <td>0.005626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.630243</td>\n",
              "      <td>0.639209</td>\n",
              "      <td>0.6469</td>\n",
              "      <td>0.006525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LinearSVCClassifier</td>\n",
              "      <td>0.616949</td>\n",
              "      <td>0.629242</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.007352</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>DecisionTreeClassifier</td>\n",
              "      <td>0.602817</td>\n",
              "      <td>0.615722</td>\n",
              "      <td>0.628678</td>\n",
              "      <td>0.010061</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    estimator min_score mean_score max_score std_score\n",
              "4  GradientBoostingClassifier  0.671135   0.683448  0.701689  0.011908\n",
              "6          AdaBoostClassifier   0.67042   0.682432  0.692969  0.008438\n",
              "1               XGBClassifier   0.67122   0.681415  0.689518   0.00696\n",
              "3      RandomForestClassifier  0.672934   0.678131  0.684739  0.005389\n",
              "5        ExtraTreesClassifier  0.668339   0.675858  0.687898  0.007283\n",
              "7       BernoulliNBClassifier  0.637037    0.64612  0.653093  0.005626\n",
              "0          LogisticRegression  0.630243   0.639209    0.6469  0.006525\n",
              "8         LinearSVCClassifier  0.616949   0.629242  0.636364  0.007352\n",
              "2      DecisionTreeClassifier  0.602817   0.615722  0.628678  0.010061"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "f1_grid_search_summary, grid_search_pipelines = f1_search.score_summary(sort_by='mean_score')\n",
        "f1_grid_search_summary "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We see that the top five algorithms are all performing fairly similarly, with a `mean_score` between 0.675 and 0.684. To start with, given limited processing capacity, we will consider a range of hyperparameters for the top two, `GradientBoostingClassifier` and `AdaBoostClassifier`.\n",
        "\n",
        "We are already familiar with `GradientBoostingClassifier` from the previous notebook and we use the same values for hyperparameter tuning as those considered in the previous iteration.\n",
        "\n",
        "`AdaBoostClassifier`, as noted in its [online documentation](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html), is \"a meta-estimator that begins by fitting a classifier on the original dataset and then fits additional copies of the classifier on the same dataset but where the weights of incorrectly classified instances are adjusted such that subsequent classifiers focus more on difficult cases\".\n",
        "* It has a limited number of hyperparameters that can be tuned, so not as many hyperparameters appear in its `params_search` below.\n",
        "* Similarly to in the other algorithms, `n_estimators` controls the number of weak learners (decision trees) to be used in the ensemble. Increasing the number of estimators can improve model performance, but it also increases the computational cost. We begin with values of 25, 50, 80 and 150.\n",
        "    - Note that 25 has been removed in an attempt to fix the `UserWarning: One or more of the test scores are non-finite` error\n",
        "* `learning_rate` determines the contribution of each weak learner to the final prediction. A lower learning rate typically requires more estimators to achieve similar performance. Here we consider values of 0.1, 1 and 2.\n",
        "* `algorithm` determines the boosting algorithm used. The SAMME.R algorithm typically converges faster than SAMME, achieving a lower test error with fewer boosting iterations, but we consider both here.\n",
        "* The `estimator` parameter determines the base estimator from which the boosted ensemble is built. Here we consider `DecisionTreeClassifier`, `RandomForestClassifier` and `ExtraTreesClassifier` to cover a range of possibilities.\n",
        "    - Instances of the base estimators are created separately and then passed to `AdaBoostClassifier`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "estimator_1 = DecisionTreeClassifier()\n",
        "estimator_2 = RandomForestClassifier()\n",
        "estimator_3 = ExtraTreesClassifier()\n",
        "\n",
        "models_search = {\n",
        "    \"AdaBoostClassifier\": AdaBoostClassifier(random_state=0),\n",
        "    \"GradientBoostingClassifier\": GradientBoostingClassifier(random_state=0),\n",
        "}\n",
        "\n",
        "params_search = {\n",
        "    \"AdaBoostClassifier\":{\n",
        "      'model__n_estimators': [25, 50, 80],\n",
        "      'model__learning_rate':[0.1, 1, 2],\n",
        "      'model__algorithm': ['SAMME', 'SAMME.R'],\n",
        "      'model__base_estimator': [estimator_1, estimator_2, estimator_3]\n",
        "    },\n",
        "    \"GradientBoostingClassifier\":{\n",
        "      'model__n_estimators': [100, 50, 140],\n",
        "      'model__learning_rate':[0.1, 0.01, 0.001],\n",
        "      'model__max_depth': [3, 15, None],\n",
        "      'model__min_samples_split': [2, 25, 50],\n",
        "      'model__min_samples_leaf': [1, 25, 50],\n",
        "      'model__max_leaf_nodes': [None, 25, 50]\n",
        "    },\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Running GridSearchCV for AdaBoostClassifier \n",
            "\n",
            "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
            "\n",
            "Running GridSearchCV for GradientBoostingClassifier \n",
            "\n",
            "Fitting 5 folds for each of 729 candidates, totalling 3645 fits\n"
          ]
        }
      ],
      "source": [
        "detail_search = HyperparameterOptimizationSearch(models=models_search, params=params_search)\n",
        "detail_search.fit(X_train, y_train,\n",
        "           scoring =  make_scorer(f1_score),\n",
        "           n_jobs=-1, cv=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "      <th>model__algorithm</th>\n",
              "      <th>model__base_estimator</th>\n",
              "      <th>model__learning_rate</th>\n",
              "      <th>model__n_estimators</th>\n",
              "      <th>model__max_depth</th>\n",
              "      <th>model__max_leaf_nodes</th>\n",
              "      <th>model__min_samples_leaf</th>\n",
              "      <th>model__min_samples_split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>586</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.684576</td>\n",
              "      <td>0.69866</td>\n",
              "      <td>0.704663</td>\n",
              "      <td>0.007206</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>616</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.684576</td>\n",
              "      <td>0.69866</td>\n",
              "      <td>0.704663</td>\n",
              "      <td>0.007206</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>589</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.684576</td>\n",
              "      <td>0.69866</td>\n",
              "      <td>0.704663</td>\n",
              "      <td>0.007206</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "      <td>50</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.684576</td>\n",
              "      <td>0.69866</td>\n",
              "      <td>0.704663</td>\n",
              "      <td>0.007206</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.684576</td>\n",
              "      <td>0.69866</td>\n",
              "      <td>0.704663</td>\n",
              "      <td>0.007206</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>50</td>\n",
              "      <td>3</td>\n",
              "      <td>None</td>\n",
              "      <td>50</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>703</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.60232</td>\n",
              "      <td>0.613963</td>\n",
              "      <td>0.626281</td>\n",
              "      <td>0.009807</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>50</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>702</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.601392</td>\n",
              "      <td>0.613791</td>\n",
              "      <td>0.626613</td>\n",
              "      <td>0.009825</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.001</td>\n",
              "      <td>100</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.60232</td>\n",
              "      <td>0.613712</td>\n",
              "      <td>0.625673</td>\n",
              "      <td>0.010005</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.01</td>\n",
              "      <td>140</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.574468</td>\n",
              "      <td>0.610566</td>\n",
              "      <td>0.639456</td>\n",
              "      <td>0.023883</td>\n",
              "      <td>SAMME</td>\n",
              "      <td>DecisionTreeClassifier()</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.573106</td>\n",
              "      <td>0.609246</td>\n",
              "      <td>0.630456</td>\n",
              "      <td>0.019795</td>\n",
              "      <td>SAMME</td>\n",
              "      <td>DecisionTreeClassifier()</td>\n",
              "      <td>2</td>\n",
              "      <td>80</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>783 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      estimator min_score mean_score max_score std_score  \\\n",
              "586  GradientBoostingClassifier  0.684576    0.69866  0.704663  0.007206   \n",
              "616  GradientBoostingClassifier  0.684576    0.69866  0.704663  0.007206   \n",
              "589  GradientBoostingClassifier  0.684576    0.69866  0.704663  0.007206   \n",
              "565  GradientBoostingClassifier  0.684576    0.69866  0.704663  0.007206   \n",
              "562  GradientBoostingClassifier  0.684576    0.69866  0.704663  0.007206   \n",
              "..                          ...       ...        ...       ...       ...   \n",
              "703  GradientBoostingClassifier   0.60232   0.613963  0.626281  0.009807   \n",
              "702  GradientBoostingClassifier  0.601392   0.613791  0.626613  0.009825   \n",
              "461  GradientBoostingClassifier   0.60232   0.613712  0.625673  0.010005   \n",
              "7            AdaBoostClassifier  0.574468   0.610566  0.639456  0.023883   \n",
              "8            AdaBoostClassifier  0.573106   0.609246  0.630456  0.019795   \n",
              "\n",
              "    model__algorithm     model__base_estimator model__learning_rate  \\\n",
              "586              NaN                       NaN                0.001   \n",
              "616              NaN                       NaN                0.001   \n",
              "589              NaN                       NaN                0.001   \n",
              "565              NaN                       NaN                0.001   \n",
              "562              NaN                       NaN                0.001   \n",
              "..               ...                       ...                  ...   \n",
              "703              NaN                       NaN                0.001   \n",
              "702              NaN                       NaN                0.001   \n",
              "461              NaN                       NaN                 0.01   \n",
              "7              SAMME  DecisionTreeClassifier()                    2   \n",
              "8              SAMME  DecisionTreeClassifier()                    2   \n",
              "\n",
              "    model__n_estimators model__max_depth model__max_leaf_nodes  \\\n",
              "586                  50                3                    25   \n",
              "616                  50                3                    50   \n",
              "589                  50                3                    25   \n",
              "565                  50                3                  None   \n",
              "562                  50                3                  None   \n",
              "..                  ...              ...                   ...   \n",
              "703                  50             None                  None   \n",
              "702                 100             None                  None   \n",
              "461                 140             None                  None   \n",
              "7                    50              NaN                   NaN   \n",
              "8                    80              NaN                   NaN   \n",
              "\n",
              "    model__min_samples_leaf model__min_samples_split  \n",
              "586                      50                        2  \n",
              "616                      50                       25  \n",
              "589                      50                       25  \n",
              "565                      50                       50  \n",
              "562                      50                       25  \n",
              "..                      ...                      ...  \n",
              "703                       1                        2  \n",
              "702                       1                        2  \n",
              "461                       1                        2  \n",
              "7                       NaN                      NaN  \n",
              "8                       NaN                      NaN  \n",
              "\n",
              "[783 rows x 13 columns]"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "grid_search_summary, grid_search_pipelines = detail_search.score_summary(sort_by='mean_score')\n",
        "grid_search_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'GradientBoostingClassifier'"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model = grid_search_summary.iloc[0,0]\n",
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'model__learning_rate': 0.001,\n",
              " 'model__max_depth': 3,\n",
              " 'model__max_leaf_nodes': None,\n",
              " 'model__min_samples_leaf': 50,\n",
              " 'model__min_samples_split': 2,\n",
              " 'model__n_estimators': 50}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_parameters = grid_search_pipelines[best_model].best_params_\n",
        "best_parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Pipeline(steps=[('scaler', StandardScaler()),\n",
              "                ('feat_selection',\n",
              "                 SelectFromModel(estimator=GradientBoostingClassifier(random_state=0))),\n",
              "                ('model',\n",
              "                 GradientBoostingClassifier(learning_rate=0.001,\n",
              "                                            min_samples_leaf=50,\n",
              "                                            n_estimators=50, random_state=0))])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipeline_clf = grid_search_pipelines[best_model].best_estimator_\n",
        "pipeline_clf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "* These are the 2 most important features in descending order. The model was trained on them: \n",
            "['total_default', 'bill_sep']\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# create DataFrame to display feature importance\n",
        "df_feature_importance = (pd.DataFrame(data={\n",
        "    'Feature': X_train.columns[pipeline_clf['feat_selection'].get_support()],\n",
        "    'Importance': pipeline_clf['model'].feature_importances_})\n",
        "    .sort_values(by='Importance', ascending=False)\n",
        ")\n",
        "\n",
        "# re-assign best_features order\n",
        "best_features = df_feature_importance['Feature'].to_list()\n",
        "\n",
        "# Most important features statement and plot\n",
        "print(f\"* These are the {len(best_features)} most important features in descending order. \"\n",
        "      f\"The model was trained on them: \\n{df_feature_importance['Feature'].to_list()}\")\n",
        "\n",
        "df_feature_importance.plot(kind='bar', x='Feature', y='Importance')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "def confusion_matrix_and_report(X, y, pipeline, label_map):\n",
        "\n",
        "    prediction = pipeline.predict(X)\n",
        "\n",
        "    print('---  Confusion Matrix  ---')\n",
        "    print(pd.DataFrame(confusion_matrix(y_true=prediction, y_pred=y),\n",
        "          columns=[[\"Actual \" + sub for sub in label_map]],\n",
        "          index=[[\"Prediction \" + sub for sub in label_map]]\n",
        "          ))\n",
        "    print(\"\\n\")\n",
        "\n",
        "    print('---  Classification Report  ---')\n",
        "    print(classification_report(y, prediction, target_names=label_map), \"\\n\")\n",
        "\n",
        "\n",
        "def clf_performance(X_train, y_train, X_test, y_test, pipeline, label_map):\n",
        "    print(\"#### Train Set #### \\n\")\n",
        "    confusion_matrix_and_report(X_train, y_train, pipeline, label_map)\n",
        "\n",
        "    print(\"#### Test Set ####\\n\")\n",
        "    confusion_matrix_and_report(X_test, y_test, pipeline, label_map)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#### Train Set #### \n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                      Actual No Default Actual Default\n",
            "Prediction No Default              3610           1513\n",
            "Prediction Default                 1713           3810\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  No Default       0.70      0.68      0.69      5323\n",
            "     Default       0.69      0.72      0.70      5323\n",
            "\n",
            "    accuracy                           0.70     10646\n",
            "   macro avg       0.70      0.70      0.70     10646\n",
            "weighted avg       0.70      0.70      0.70     10646\n",
            " \n",
            "\n",
            "#### Test Set ####\n",
            "\n",
            "---  Confusion Matrix  ---\n",
            "                      Actual No Default Actual Default\n",
            "Prediction No Default              3193            391\n",
            "Prediction Default                 1494            922\n",
            "\n",
            "\n",
            "---  Classification Report  ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "  No Default       0.89      0.68      0.77      4687\n",
            "     Default       0.38      0.70      0.49      1313\n",
            "\n",
            "    accuracy                           0.69      6000\n",
            "   macro avg       0.64      0.69      0.63      6000\n",
            "weighted avg       0.78      0.69      0.71      6000\n",
            " \n",
            "\n"
          ]
        }
      ],
      "source": [
        "clf_performance(X_train=X_train, y_train=y_train,\n",
        "                X_test=X_test, y_test=y_test,\n",
        "                pipeline=pipeline_clf,\n",
        "                label_map= ['No Default', 'Default'] \n",
        "                )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Push files to Repo"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [
        {
          "ename": "IndentationError",
          "evalue": "expected an indented block (2852421808.py, line 5)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;36m  Cell \u001b[1;32mIn[19], line 5\u001b[1;36m\u001b[0m\n\u001b[1;33m    except Exception as e:\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
